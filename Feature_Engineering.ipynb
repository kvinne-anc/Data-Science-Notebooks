{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature_Engineering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kvinne-anc/Data-Science-Notebooks/blob/main/Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fknoKxGz_jk"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 1, Sprint 1, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qacqiXogluN_"
      },
      "source": [
        "# Make Features \n",
        "\n",
        "- Student should be able to understand the purpose of feature engineering\n",
        "- Student should be able to work with strings in pandas\n",
        "- Student should be able to work with dates and times in pandas\n",
        "- Student should be able to modify or create columns of a dataframe using the `.apply()` function\n",
        "\n",
        "\n",
        "Helpful Links:\n",
        "- [Minimally Sufficient Pandas](https://medium.com/dunder-data/minimally-sufficient-pandas-a8e67f2a2428)\n",
        "- [Feature Engineering](https://en.wikipedia.org/wiki/Feature_engineering)\n",
        "- Python Data Science Handbook\n",
        "  - [Chapter 3.10](https://jakevdp.github.io/PythonDataScienceHandbook/03.10-working-with-strings.html), Vectorized String Operations\n",
        "  - [Chapter 3.11](https://jakevdp.github.io/PythonDataScienceHandbook/03.11-working-with-time-series.html), Working with Time Series\n",
        "- [Lambda Learning Method for DS - By Ryan Herr](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZSXUzBm3yvk"
      },
      "source": [
        "# [Objective](#feature-engineering) - The Purpose of Feature Engineering\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGHzNUcT30ui"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Feature Engineering is the process of using a combination of domain knowledge, creativity and the pre-existing columns of a dataset to create completely new columns.\n",
        "\n",
        " Machine Learning models try to detect patterns in the data and then associate those patterns with certain predictions. The hope is that by creating new columns on our dataset that we can expose our model to new patterns in the data so that it can make better and better predictions.\n",
        "\n",
        "This is largely a matter of understanding how to work with individual columns of a dataframe with Pandas --which is what we'll be practicing today!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6vOmj_i35ef"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "Columns of a dataframe hold each hold a specific type of data. Lets inspect some of the common datatypes found in datasets and then we'll make a new feature on a dataset using pre-existing columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua6VURnC9Cny"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_Y05YBr32O-"
      },
      "source": [
        "# Lets take a look at the Ames Iowa Housing Dataset:\n",
        "source_url = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/Ames%20Housing%20Data/train.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SQzyD_okiWQ"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "iowa = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/Ames%20Housing%20Data/train.csv')\n",
        "iowa.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9d3VtCcj1Zu"
      },
      "source": [
        "# first few rows\n",
        "iowa.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5C1Cmtsj7jM"
      },
      "source": [
        "# shape\n",
        "iowa.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "febRjE6jj_lZ"
      },
      "source": [
        "# describe\n",
        "iowa.describe\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QmscJ7n9OSB"
      },
      "source": [
        "### Specific Columns hold specific kinds of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8rsw3zl9S3v",
        "scrolled": true
      },
      "source": [
        "# column types\n",
        "# pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_rows', 400) \n",
        "\n",
        "iowa.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znph8qpr9q29"
      },
      "source": [
        "Some columns hold integer values like the `BedroomAbvGr` which stands for \"Bedrooms Above Grade.\" This is the number of non-basement bedrooms in the home.\n",
        "\n",
        "For more information on specific column meanings view the [data dictionary](https://github.com/ryanleeallred/datasets/blob/master/Ames%20Housing%20Data/data_description.txt)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl-wfFZv-_fo"
      },
      "source": [
        "# Look at the first ten rows of the `BedroomAbvGr` column.\n",
        "# Looks like integers to me!\n",
        "iowa['BedroomAbvGr'].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4D3kky4lMId"
      },
      "source": [
        "# another way to call columns: dot method\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdoemcyUv4HS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyfxM5tc_Q1w"
      },
      "source": [
        "Some columns hold float values like the `LotFrontage` column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdILA65r_PeY"
      },
      "source": [
        "# Look at the first ten rows of the `BedroomAbvGr` column.\n",
        "iowa['BedroomAbvGr'].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfvyHa9IfGi9"
      },
      "source": [
        "Hmmm, do the values above look like floats to you?\n",
        "\n",
        "They all have .0 on them so technically they're being stored as floats, but *should* they be stored as floats?\n",
        "\n",
        "Lets see what all of the possible values for this column are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDLnz1CX_eGc",
        "scrolled": true
      },
      "source": [
        "iowa['LotFrontage'].value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IaYU5QzAfgn"
      },
      "source": [
        "Looks to me like the `LotFrontage` column originally held integer values but was cast to a `float` meaning that each original integer values was converted to its corresponding float representation. \n",
        "\n",
        "Any guesses as to why that would have happened?\n",
        "\n",
        "\n",
        "HINT: What's the most common `LotFrontage` value for this column?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtkV149OA5je"
      },
      "source": [
        "# NaN is the most common value in this column. What is a NaN\n",
        "iowa['LotFrontage'].value_counts(dropna=False).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNKPLl_BQh7"
      },
      "source": [
        "`NaN` stands stands for \"Not a Number\" and is the default missing value indicator with Pandas. This means there were cells in this column that didn't have a LotFrontage value recorded for those homes. \n",
        "\n",
        "This is where domain knowledge starts to come in. Think about the context we're working with here: houses. What might a null or blank cell representing \"Linear feet of street connected to property\" mean in the context of a housing dataset?\n",
        "\n",
        "Ok, so maybe it makes seanse to have some NaNs in this column. What is the datatype of a NaN value?\n",
        "\n",
        "Perhaps some of this data is truly missing or unrecorded data, but sometimes `NaNs` are more likely to indicate something that was \"NA\" or \"Not Applicable\" to a particular observation. There could be multiple reasons why there was no value recorded for a particular feature.\n",
        "\n",
        "Remember, that Pandas tries to maintain a single datatype for all values in a column, and therefore..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2166y9kXB0zZ"
      },
      "source": [
        "# What is the datatype of NaN?\n",
        "import numpy as np \n",
        "type(np.NaN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37ZaBu5OB63d"
      },
      "source": [
        "The datatype of a NaN is float!  This means that if we have a column of integer values, but the column has even a single `NaN` that column will not be treated with the integer datatype but all of the integers will be converted to floats in order to try and preserve the same datatype throughout the entire column.\n",
        "\n",
        "You can see already how understanding column datatypes is crucial to understanding how Pandas help us manage our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRd6DMqceUb7"
      },
      "source": [
        "# how much missing data\n",
        "iowa.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS5lVt0weUb_"
      },
      "source": [
        "# drop missing data\n",
        "iowa.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2nSbEfFeUcD"
      },
      "source": [
        "# now how much missing data is there\n",
        "\n",
        "iowa.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3SicLbIgFvk"
      },
      "source": [
        "iowa['LotFrontage'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56DbXV5pgPa8"
      },
      "source": [
        "#no missing data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko_yfcFqg0pj"
      },
      "source": [
        "### Making new Features\n",
        "\n",
        "Lets slim down the dataset and consider just a few specific columns:\n",
        "\n",
        "- `TotalBsmtSF`\n",
        "- `1stFlrSF`\n",
        "- `2ndFlrSF`\n",
        "- `SalePrice1`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GxPTgevhWnv"
      },
      "source": [
        "# I can make a smaller dataframe with a few specific column headers\n",
        "# by passing a list of column headers inside of the square brackets\n",
        "small_iowa = iowa[['TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'SalePrice']]\n",
        "\n",
        "small_iowa.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw0PzxkbiQmm"
      },
      "source": [
        "### Syntax for creating new columns\n",
        "\n",
        "When making a new column on a dataframe, we have to use the square bracket syntax of accessing a column. We can't use \"dot syntax\" here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkXHP57_iJ-U"
      },
      "source": [
        "# Lets add up all of the square footage to get a single square footage \n",
        "# column for the entire dataset\n",
        "small_iowa['TotalSquareFootage'] = small_iowa['TotalBsmtSF'] + small_iowa['1stFlrSF'] + small_iowa['2ndFlrSF']\n",
        "\n",
        "small_iowa.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR-KId2zwEiN"
      },
      "source": [
        "# Using bracket syntax to make a new 'TotalSquareFootage' column\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEy-6VQCi08c"
      },
      "source": [
        "# Lets make a nother new column that is 'PricePerSqFt' by\n",
        "# dividing the price by the square footage\n",
        "small_iowa['PricePerSqFt'] = (small_iowa['SalePrice'] / small_iowa['TotalSquareFootage'])\n",
        "\n",
        "small_iowa.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ-GGFwKkPjF"
      },
      "source": [
        "Ok, we have made two new columns on our small dataset.\n",
        "\n",
        "- What does a **high** `PricePerSqFt` say about a home that the square footage and price alone don't capture as directly?\n",
        "\n",
        "- What does a **low** `PricePerSqFt` say about a home that the square footage and price alone don't directly capture?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye5nZtRSeUcS"
      },
      "source": [
        "## crosstabs\n",
        "#focus on categorical variables \n",
        "iowa.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m76Y5MbEpH2S"
      },
      "source": [
        "# what are some categorical columns?\n",
        "iowa[['LotShape', 'Alley', 'Street', 'SaleCondition']].sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChkyRkbPpYRU"
      },
      "source": [
        "# values of sale condition\n",
        "iowa['SaleCondition'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r74GxXFphAa"
      },
      "source": [
        "# create a new categorical variable\n",
        "iowa['NormalCondition'] = np.where(iowa['SaleCondition']=='Normal', 'yes', 'no')\n",
        "iowa['NormalCondition'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LErT4D6reUcV"
      },
      "source": [
        "# value counts of a categorical variable\n",
        "iowa['LotShape'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COB8JesgqCS_"
      },
      "source": [
        "# Map this from four down to 3 values\n",
        "iowa['LotShape3'] = iowa['LotShape'].map({'Reg':'Regular',\n",
        "                                          'IR1':'Irregular',\n",
        "                                          'IR2':'Other',\n",
        "                                          'IR3':'Other'})\n",
        "iowa['LotShape3'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4HdfkTTqXZE"
      },
      "source": [
        "# values\n",
        "iowa['Neighborhood'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaAeUgG4eUcY"
      },
      "source": [
        "# value counts of a categorical variable\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xha1GyOgq23p"
      },
      "source": [
        "# one more way to map categorical variables\n",
        "# replace using .loc \n",
        "\n",
        "iowa['Top_Neighborhood']='All Others'\n",
        "iowa[['Top_Neighborhood', 'Neighborhood']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sF3oR6mrObm"
      },
      "source": [
        "iowa.loc[iowa['Neighborhood']=='NAmes', 'Top_Neighborhood']='North Ames'\n",
        "iowa[['Top_Neighborhood', 'Neighborhood']].sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNRN1OlusBrh"
      },
      "source": [
        "iowa.loc[iowa['Neighborhood']=='CollgCr', 'Top_Neighborhood']='College Circle'\n",
        "iowa[['Top_Neighborhood', 'Neighborhood']].sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MahlMoebsyiz"
      },
      "source": [
        "iowa['Top_Neighborhood'].value_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLX7_1Q0eUcb"
      },
      "source": [
        "# crosstab!\n",
        "pd.crosstab(iowa['Top_Neighborhood'], iowa['LotShape3'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54sTiehOeUce"
      },
      "source": [
        "# margins\n",
        "pd.crosstab(iowa['Top_Neighborhood'], iowa['LotShape3'], margins=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKMSqP8PeUch"
      },
      "source": [
        "# as proportions\n",
        "\n",
        "pd.crosstab(iowa['Top_Neighborhood'], iowa['LotShape3'], normalize='index', margins=True)\n",
        "pd.crosstab(iowa['Top_Neighborhood'], iowa['LotShape3'], normalize='columns', margins=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH_mN7uReUck"
      },
      "source": [
        "# display that\n",
        "myresults = pd.crosstab(iowa['Top_Neighborhood'], iowa['LotShape3'])\n",
        "myresults.plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyVWt5Apuekv"
      },
      "source": [
        "pd.crosstab(iowa['OverallQual'], iowa['Top_Neighborhood'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a14DomKheUcn"
      },
      "source": [
        "# Flip that\n",
        "\n",
        "myresults.plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BbCu3ii4LK8"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "I hope you can see how we have used existing columns to create a new column on a dataset that say something new about our unit of observation. This is what making new features (columns) on a dataset is all about and why it's so essential to data science --particularly predictive modeling \"Machine Learning.\" \n",
        "\n",
        "We'll spend the rest of the lecture and assignment today trying to get as good as we can at manipulating (cleaning) and creating new columns on datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKnLv6nGmU8N"
      },
      "source": [
        "# [Objective](#work-with-strings) Work with Strings with Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqd_Lpb9ntwT"
      },
      "source": [
        "## Overview\n",
        "\n",
        "So far we have worked with numeric datatypes (ints and floats) but we haven't worked with any columns containing string values. We can't simply use arithmetic to manipulate string values, so we'll need to learn some more techniques in order to work with this datatype."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6UBXPhQnxzj"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "We're going to import a new dataset here to work with. This dataset is from LendingClub and holds information about loans issued in Q4 of 2018. This dataset is a bit messy so it will give us plenty of opportunities to clean up existing columns as well as create new ones.\n",
        "\n",
        "The `!wget` shell command being used here does exactly the same thing that your browser does when you type a URL in the address. It makes a request or \"gets\" the file at that address. However, in our case the file isn't a webpage, it's a compressed CSV file. \n",
        "\n",
        "Try copying and pasting the URL from below into your browser, did it start an automatic download? Any URLs like this that start automatic downloads when navigated to can be used along with the `!wget` command to bring files directly into your notebook's memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1SkaCMTsCyT"
      },
      "source": [
        "### Load a new dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeEKWHB0n2fq"
      },
      "source": [
        "! wget https://resources.lendingclub.com/LoanStats_2018Q4.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqUSbgIJqAB8"
      },
      "source": [
        "We need to use the `!unzip` command to extract the csv from the zipped folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbw0l5wyqLeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b78c36-c218-4999-aadb-7874dc500a62"
      },
      "source": [
        "!unzip LoanStats_2018Q4.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  LoanStats_2018Q4.csv.zip\n",
            "replace LoanStats_2018Q4.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_bEBsHTqduT"
      },
      "source": [
        "As we look at the raw file itself, do you see anything that might cause us trouble as we read in the CSV file to a dataframe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikpjHKeiqlWp"
      },
      "source": [
        "# Read in the CSV\n",
        "loans = pd.read_csv('LoanStats_2018Q4.csv.zip')\n",
        "loans.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvqwNrQlq5fr"
      },
      "source": [
        "The extra rows at the top and bottom of the file have done two things:\n",
        "\n",
        "1) The top row has made it so that the entire dataset is being interpreted as column headers\n",
        "\n",
        "2) The bottom two rows have been read into the 'id' column and are causing every column to have at least two `NaN` values in it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n3VrzcYwkl9"
      },
      "source": [
        "loans = pd.read_csv('LoanStats_2018Q4.csv.zip', header=1, skipfooter=2, engine='python')\n",
        "loans.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzZMWvWnwqUP"
      },
      "source": [
        "loans.tail()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKM5P0RzrLh8"
      },
      "source": [
        "# We can fix the header problem by using the 'skiprows' parameter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuLO7bhTrY0z"
      },
      "source": [
        "Lets look at the NaN values of each column so that you can see the problem that the extra rows at the bottom of the file are creating for us"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12OtVOd9rdb-"
      },
      "source": [
        "# Sum null values by column and sort from least to greatest\n",
        "loans.isnull().sum().sort_values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4793LweyroFI"
      },
      "source": [
        "# Address the extra NaNs in each column by skipping the footer as \n",
        "\n",
        "loans = pd.read_csv('LoanStats_2018Q4.csv.zip',\n",
        "                    skiprows=1,\n",
        "                    skipfooter=2,\n",
        "                    engine='python')\n",
        "\n",
        "print(loans.shape)\n",
        "loans.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQtUG_tc8H1Y"
      },
      "source": [
        "loans.isnull().sum().sort_values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzPuC7jUstVF"
      },
      "source": [
        "For good measure, we'll also drop some columns that are made up completely of NaN values.\n",
        "\n",
        "Why might LendingClub have included columns in their dataset that are 100% blank?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HubXTHZ3sj6n"
      },
      "source": [
        "loans1 = loans.drop(['url', 'member_id', 'desc', 'id'], axis=1)\n",
        "\n",
        "print(loans1.shape)\n",
        "loans1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOZrkAWaqR1o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87lzDxnCr_6j"
      },
      "source": [
        "### Clean up the `int_rate` column\n",
        "\n",
        "When we're preparing a dataset for a machine learning model we typically want to represent don't want to leave any string values in our dataset --because it's hard to do math on words. \n",
        "\n",
        "Specifically, we have a column that is representing a numeric value, but currently doesn't have a numeric datatype. Lets look at the first 10 values of the `int_rate` column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQRxQs3-tnup"
      },
      "source": [
        "# Look at the first 10 values of the int_rate column\n",
        "\n",
        "loans1['int_rate'][:10]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu2lMR4wtt-M"
      },
      "source": [
        "# Look at a specific value from the int_rate column\n",
        "loans1['int_rate'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umnBqFa0t22W"
      },
      "source": [
        "Problems that we need to address with this column:\n",
        "\n",
        "- String column that should be numeric\n",
        "- Percent Sign `%` included with the number\n",
        "- Leading space at the beginning of the string\n",
        "\n",
        "However, we're not going to try and write exactly the right code to fix this column in one go. We're going to methodically build up to the code that will help us address these problems.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qveVttHSuVlh"
      },
      "source": [
        "# Lets start with just fixing a single string.\n",
        "# If we can fix one, we can usually fix all of them\n",
        "int_rate = '16.4%'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfFY8nGluouN"
      },
      "source": [
        "# remove leading space\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZMu0IG--Spv"
      },
      "source": [
        "int_rate.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9q8syZr-WiZ"
      },
      "source": [
        "int_rate.strip('%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3bRlDUbus9m"
      },
      "source": [
        "# remove percent\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRc9KcGv-W4B"
      },
      "source": [
        "int_rate.strip().strip('%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA-FB2WEuvZr"
      },
      "source": [
        "# remove both\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jmQZgnQ-rni"
      },
      "source": [
        "type(int_rate.strip().strip('%'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJd71Boou40s"
      },
      "source": [
        "# \"Cast\" the string value to a float\n",
        "float(int_rate.strip().strip('%'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrGgRuAA_MS0"
      },
      "source": [
        "type(float(int_rate.strip().strip('%')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_bTzHIJvc8M"
      },
      "source": [
        "### Write a function to make our solution reusable!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYJYsfQZvVcK"
      },
      "source": [
        "# Write a function that can do what we have written above to any \n",
        "# string that is passsed to i\n",
        "def int_rate_to_float(cell_contents):\n",
        "  return float(cell_contents.strip().strip('%'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng3lQFD8vxQt"
      },
      "source": [
        "# Test out our function by calling it on\n",
        "  int_rate_to_float(int_rate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cPxk1W9v2ul"
      },
      "source": [
        "# is the data type correct?\n",
        "type(int_rate_to_float(int_rate))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgxdjRqnv-ZH"
      },
      "source": [
        "### Apply our solution to every cell in a column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVapzvpOA39G"
      },
      "source": [
        "loans1['int_rate_float'] = loans1['int_rate'].apply(int_rate_to_float)\n",
        "\n",
        "loans1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPPKDvBgJPI4"
      },
      "source": [
        "#for loop:\n",
        "new_list=[]\n",
        "for cell in loans['int_rate']:\n",
        "  new_list.append(int_rate_to_float(cell))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YcWIbqnJOs8"
      },
      "source": [
        "#look at first 10 values of that list\n",
        "\n",
        "new_list[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnEbXUoFz6me"
      },
      "source": [
        "# compare to original values\n",
        "loans['int_rate'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW6Q-ROCs5pu"
      },
      "source": [
        "# convert that list to a new column\n",
        "loans['int_rate_clean']=pd.Series(new_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoTbX-ncLhzt"
      },
      "source": [
        "#comparison \n",
        "loans[['int_rate', 'int_rate_clean']].sample(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYCez3j5wLWt"
      },
      "source": [
        "# What type of data is held in our new column?\n",
        "loans['int_rate_clean'].dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxkzSCuLJlfj"
      },
      "source": [
        "There is a better way! \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55S13M5utfhl"
      },
      "source": [
        "# improve all of this code with the .apply function!\n",
        "loans['int_rate_clean2'] = loans['int_rate'].apply(int_rate_to_float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHPDwCe8MS-f"
      },
      "source": [
        "#comparison\n",
        "loans[['int_rate', 'int_rate_clean', 'int_rate_clean2']].sample(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOXkc5own3LM"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "We can create a new column with our cleaned values or overwrite the original, whatever we think best suits our needs. On your assignment you will take the same approach in trying to methodically build up the complexity of your code until you have a few lines that will work for any cell in a column. At that point you'll contain all of that functionality in a reusable function block and then use the `.apply()` function to... well... apply those changes to an entire column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cllyKRVOmZW1"
      },
      "source": [
        "# [Objective](#pandas-apply) Modify and Create Columns using `.apply()`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43763DCYnucE"
      },
      "source": [
        "## Overview\n",
        "\n",
        "We're already seen one example of using the `.apply()` function to clean up a column. Lets see if we can do it again, but this time on a slightly more complicated use case.\n",
        "\n",
        "Remember, the goal here is to write a function that will work correctly on any **individual** cell of a specific column. Then we can reuse that function on those individual cells of a dataframe column via the `.apply()` function.\n",
        "\n",
        "Lets clean up the emp_title \"Employment Title\" column!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFXxzA7mnyhH"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "First we'll try and diagnose how bad the problem is and what improvements we might be able to make."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzkCNMOnxl4h"
      },
      "source": [
        "# Look at the top 20 employment titles\n",
        "loans['emp_title'].head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RlGBK5c2QBS"
      },
      "source": [
        "# look at the top 20 rows\n",
        "loans['emp_title'].value_counts(dropna=False).head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja4Qul02x0Tk"
      },
      "source": [
        "# How many different unique employment titles are there currently?\n",
        "print(loans.shape)\n",
        "len(loans['emp_title'].unique())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ5HN5pR2yvx"
      },
      "source": [
        "# another way to do this\n",
        "\n",
        "loans['emp_title'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1tC-Otax9R3"
      },
      "source": [
        "# How often is the employment_title null?\n",
        "loans['emp_title'].isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UddpRG2OyDzC"
      },
      "source": [
        "What are some possible reasons as to why a person's employment title may have not been provided?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "331sx2kVyMwz"
      },
      "source": [
        "# Create some examples that represent the cases that we want to clean up\n",
        "examples = ['owner', 'Supervisor', 'Project Manager', np.nan]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8XmlS833euz"
      },
      "source": [
        "# do that same function in individual steps\n",
        "\n",
        "type('Supervisor')\n",
        "isinstance('Supervisor', str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D9Zl7SK3fBn"
      },
      "source": [
        "# what about the strip?\n",
        "\n",
        "'Supervisor'.title().strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEIPIOUIyUDH"
      },
      "source": [
        "# Write a function to clean up these use cases and increase uniformity.\n",
        "def clean_title(jobtitle):\n",
        "  if isinstance(jobtitle, str):\n",
        "    return (jobtitle.title().strip())\n",
        "  else:\n",
        "      return 'Unknown'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6HCNFro4Wsa"
      },
      "source": [
        "# test our function\n",
        "clean_title(' SuperviSOR')\n",
        "clean_title(np.nan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPYWuuYsvzdB"
      },
      "source": [
        "# create a for loop:\n",
        "mylist = []\n",
        "for jobtitle in examples:\n",
        "  mylist.append(clean_title(jobtitle))\n",
        "mylist\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn6jfPUTylvH"
      },
      "source": [
        "# list comprehensions can combine function calls and for loops over lists\n",
        "# into one succinct and fairly readable single line of code.\n",
        "\n",
        "[clean_title(jobtitle) for jobtitle in examples]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNGJgOL4y0y7"
      },
      "source": [
        "# We have a function that works as expected. Lets apply it to our column.\n",
        "# This time we'll overwrite the original column\n",
        "\n",
        "loans['clean_title'] = loans['emp_title'].apply(clean_title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy4e9H3a7apZ"
      },
      "source": [
        "# check our work\n",
        "loans[['emp_title', 'clean_title']].head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPm26DvFzQak"
      },
      "source": [
        "We can use the same code as we did earlier to see how much progress was made.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKMEkrbFzGPL"
      },
      "source": [
        "# Look at the top 20 employment titles\n",
        "loans['emp_title'].head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM0oa-10zVCn"
      },
      "source": [
        "# How many different unique employment titles are there currently?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfK4957-76nZ"
      },
      "source": [
        "# recoding a categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKcjoiWgze2x"
      },
      "source": [
        "# How often is the employment_title null (NaN)?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj8G-tVKn36v"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Using the .apply() function isn't always about creating new columns on a dataframe, we can use it to clean up or modify existing columns as well. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0G8Kv-MmaHh"
      },
      "source": [
        "# [Objective](#dates-and-times) Work with Dates and Times with Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "565Xjo-RnvLm"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Pandas has its own datatype datatype that makes it extremely convenient to convert strings that are in standard date formates to datetime objects and then use those datetime objects to either create new features on a dataframe or work with the dataset in a timeseries fashion. \n",
        "\n",
        "This section will demonstrate how to take a column of date strings, convert it to a datetime object and then use the datetime formatting `.dt` to access specific parts of the date (year, month, day) to generate useful columns on a dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpoU_2Gknzbz"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoQ86d_R79J6"
      },
      "source": [
        "### Work with Dates \n",
        "\n",
        "pandas documentation\n",
        "- [to_datetime](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html)\n",
        "- [Time/Date Components](https://pandas.pydata.org/pandas-docs/stable/timeseries.html#time-date-components) \"You can access these properties via the `.dt` accessor\"\n",
        "\n",
        "Many of the most useful date columns in this dataset have the suffix `_d` to indicate that they correspond to dates.\n",
        "\n",
        "We'll use a list comprehension to print them out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciwfqdrcRtMk"
      },
      "source": [
        "loans.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiQl-erY9YKY"
      },
      "source": [
        "# list all columns\n",
        "loans.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Scikz4Pw9kmS"
      },
      "source": [
        "# check out one column\n",
        "loans['issue_d'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxOhEaEX76mY"
      },
      "source": [
        "# as a for loop:\n",
        "mylist = []\n",
        "for col in loans.columns:\n",
        "  if col.endswith('_d'):\n",
        "    mylist.append(col)\n",
        "mylist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPVsCVFzyDm0"
      },
      "source": [
        "# as a list comprehension:\n",
        "my_date_cols = [col for col in loans.columns if col.endswith('_d')]\n",
        "my_date_cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wccaSfx9Zo4"
      },
      "source": [
        "Lets look at the string format of the `issue_d` column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVYeLIOm9dQ-"
      },
      "source": [
        "# dtype\n",
        "type(loans['issue_d'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuQasRqw-S2d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnjOcU5y9iZh"
      },
      "source": [
        "Because this string format %m-%y is a common datetime format, we can just let Pandas detect this format and translate it to the appropriate datetime object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBV3Ta_79qe6"
      },
      "source": [
        "# infer_datetime_format=True\n",
        "loans['new_issue_d'] = pd.to_datetime(loans['issue_d'], infer_datetime_format=True)\n",
        "\n",
        "loans[['issue_d', 'new_issue_d']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-klixw-5_Ojo"
      },
      "source": [
        "# check our work\n",
        "type(loans['new_issue_d'][3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYG2ebz5TzaM"
      },
      "source": [
        "print(loans['new_issue_d'].dtype)\n",
        "loans['new_issue_d'].dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hcypFMu9y4s"
      },
      "source": [
        "Now we can see that the `issue_d` column has been changed to hold `datetime` objects.\n",
        "\n",
        "Lets look at one of the cells specifically to see what a datetime object looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUMjhnyJ94is"
      },
      "source": [
        "loans['new_issue_d'].head(1).values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZQiLh4O-CMN"
      },
      "source": [
        "You can see how the month and year have been indicated by the strings that were contained in the column previously, and that the rest of the values have been inferred."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_PhaWzb-J7X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3rKmrzY-NsD"
      },
      "source": [
        "We can use the `.dt` accessor to now grab specific parts of the datetime object. Lets grab just the year from the all of the cells in the `issue_d` column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4479qzj-Yj5"
      },
      "source": [
        "loans['year'] = loans['new_issue_d'].dt.year\n",
        "loans[['issue_d', 'new_issue_d', 'year']].head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coNYQvdJ-b0s"
      },
      "source": [
        "Now the month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D28keYR3-dJn"
      },
      "source": [
        "loans['month'] = loans['new_issue_d'].dt.month\n",
        "loans[['issue_d', 'new_issue_d', 'year', 'month']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szYK1DdGz1Ph"
      },
      "source": [
        "# look at their types!\n",
        "\n",
        "loans['weekday'] = loans['new_issue_d'].dt.weekday\n",
        "loans[['issue_d', 'new_issue_d', 'year', 'month', 'weekday']].sample(8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4_O0q0t-hOX"
      },
      "source": [
        "It's just that easy! Now, instead of printing them out, lets add these year and month values as new columns on our dataframe. Again, you'll have to scroll all the way over to the right in the table to see the new columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJdlhqH1-mri"
      },
      "source": [
        "# same thing, diff var\n",
        "loans['new_pull'] = pd.to_datetime(loans['last_credit_pull_d'])\n",
        "loans['month'] = loans['new_issue_d'].dt.month\n",
        "loans[['issue_d', 'new_issue_d', 'year', 'month']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAxig0nE-1kt"
      },
      "source": [
        "Because all of these dates come from Q4 of 2018, the `issue_d` column isn't all that interesting. Lets look at the `earliest_cr_line` column, which is also a string, but that could be converted to datetime format.\n",
        "\n",
        "We're going to create a new column called `days_from_earliest_credit_to_issue`\n",
        "\n",
        "It's a long column header, but think about how valuable this piece of information could be. This number will essentially indicate the length of a person's credit history and if that is correlated with repayment or other factors could be a valuable predictor!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S6BDZjp-e8-"
      },
      "source": [
        "# date arithmetic\n",
        "loans['day_diff'] = loans['new_issue_d'] - loans['new_pull']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Drj8BK0lE9"
      },
      "source": [
        "# check that out\n",
        "loans[['last_credit_pull_d', 'new_pull', 'day_diff']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0VwXV1F_YpZ"
      },
      "source": [
        "loans['day_diff'].value_counts().sort_index().tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml-N769C_e_n"
      },
      "source": [
        "What we're about to do is so cool! Pandas' datetime format is so smart that we can simply use the subtraction operator `-` in order to calculate the amount of time between two dates. \n",
        "\n",
        "Think about everything that's going on under the hood in order to give us such straightforward syntax! Handling months of different lengths, leap years, etc. Pandas datetime objects are seriously powerful!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWu1a57V_cHx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvRjLKZo_XRq"
      },
      "source": [
        "loans['earliest_cr_line'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHQEQZx6_3_p"
      },
      "source": [
        "What's oldest credit history that was involved in Q4 2018? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrEqk6hG_20O"
      },
      "source": [
        "loans['earliest_cr_line'].tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylcYUlySYUhr"
      },
      "source": [
        "loans['earliest_cr_line'] = pd.to_datetime(loans['earliest_cr_line'], \n",
        "                                        infer_datetime_format=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FnImTAyigtj"
      },
      "source": [
        "loans.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rHzkkmVc-tm"
      },
      "source": [
        "loans['days_from_earliest_credit_to_issue'] = round((loans['new_issue_d'] - loans['earliest_cr_line']).dt.days / 365, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaFoUkNBYuae"
      },
      "source": [
        "loans['days_from_earliest_credit_to_issue'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9WpOvvRYulG"
      },
      "source": [
        "#I don't know how to change the it to make the arrays match - so confused but need to finish "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsW1tpoSdiXS"
      },
      "source": [
        "#I searched Stackoverflow to figure out why I was getting an attribute error 'timedelta properties' and I discovered that month and years are not dateime attributes because they are not uniformily defined. \n",
        "#I used 'round' to workaround the issue. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9ZHp4xSYu2D"
      },
      "source": [
        "#Convert the term column from string to integer.\n",
        "loans['term'] = loans['term'].astype(str)\n",
        "loans['term'].dtype\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUSSzAhOhCwI"
      },
      "source": [
        "loans.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bslwFlJgfqUa"
      },
      "source": [
        "#Make a column named loan_status_is_great. \n",
        "\n",
        "\n",
        "loans['loan_status_is_great'] = (loans.loan_amnt - loans.funded_amnt)\n",
        "loans['loan_status_is_great'].sample(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJHVcRW7fsmr"
      },
      "source": [
        "#It should contain the integer 1 if loan_status is \"Current\" or \"Fully Paid.\" \n",
        "#take another look at 'if than' 'for' 'else' statements \n",
        "loans['loan_status'].head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abETKnDrfwQY"
      },
      "source": [
        "\n",
        "#Make last_pymnt_d_month and last_pymnt_d_year columns.\n",
        "#Search the beginning again and see how best to define these\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gORWK62cAF2a"
      },
      "source": [
        "25,171 days is ~ 68.96 years of credit history!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THRLJ-7Jn4om"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Pandas' datetime format is so easy to work with that there's really no excuse for not using dates to make features on a dataframe! Get ready to practice more of this on your assignment."
      ]
    }
  ]
}